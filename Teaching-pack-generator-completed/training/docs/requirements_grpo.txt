# GRPO Training Requirements

# Core libraries
torch>=2.0.0
transformers>=4.36.0
datasets>=2.14.0
accelerate>=0.24.0
peft>=0.7.0
trl>=0.7.10

# Quantization
bitsandbytes>=0.41.0

# Training utilities
tensorboard
wandb
scipy

# Optional but recommended
flash-attn>=2.3.0  # For faster attention (requires compatible GPU)
xformers  # Alternative attention implementation

# Data processing
pandas
numpy
